核心流程：

1. 初始化服务端监听线程ServerSocketChannel，注册到selector同时关注OP_ACCEPT
2. 启动ServerSocketChannel线程，用来处理与客户端的IO操作
3. 如果有接收到客户端connect请求，处理OP_ACCEPT事件，封装SocketChannel与SelectionKey为NIOServerCnxn组件代表与一个客户端的连接，并attach到SelectionKey上，最后维护好连接后注册到selector同时关注OP_READ
4. 如果有数据可以读取或者发送则通过SelectionKey的attachment获取到对应NIOServerCnxn来执行对客户端的IO操作
5. 如果有数据需要发送，在发送数据到连接对应的outgoingBuffers队列后，让连接对应的SelectionKey关注OP_WRITE，下一次执行IO的时候就会执行OP_WRITE事件，直到队列数据全部发送完成

# 服务端NIO通信流程

## 服务端监听线程NIOServerCnxnFactory

NIOServerCnxnFactory是zk服务端用来处理客户端连接的组件，本身是一个线程，在服务进程初始化QuorumPeerMain类的时候，就会对ServerCnxnFactory进行初始化，启动后会不停地循环通过NIO多路复器接受来自客户端的请求，并进行IO处理

```java
public void runFromConfig(QuorumPeerConfig config) throws IOException {

    ...
    //默认创建的是NIOServerCnxnFactory用来接收客户端的连接
    ServerCnxnFactory cnxnFactory = ServerCnxnFactory.createFactory();
    //配置server监听的ip与端口号，默认2181
    cnxnFactory.configure(config.getClientPortAddress(),config.getMaxClientCnxns());
    
    quorumPeer.setCnxnFactory(cnxnFactory);
    ...
}
```

服务端ServerSocketChannel创建后注册到Selector上并关注OP_ACCEPT事件，等待处理客户端发起的connect连接

```java
public class NIOServerCnxnFactory extends ServerCnxnFactory implements Runnable {

    ...
    @Override
    public void configure(InetSocketAddress addr, int maxcc) throws IOException {
        configureSaslLogin();

        thread = new Thread(this, "NIOServerCxn.Factory:" + addr);
        thread.setDaemon(true);
        //默认客户端连接数最大为64
        maxClientCnxns = maxcc;
        //创建ServerSocketChannel
        this.ss = ServerSocketChannel.open();
        //当连接关闭的时候socket会处于一段时间的TIME_WAIT状态，会导致无法再次绑定该地址和端口号
        //设置为true后可以在socket关闭后随时再次启动绑定地址和端口
        ss.socket().setReuseAddress(true);
        LOG.info("binding to port " + addr);
        ss.socket().bind(addr);
        //配置NIO非阻塞
        ss.configureBlocking(false);
        //注册到Selector上，并关注accept事件
        ss.register(selector, SelectionKey.OP_ACCEPT);
    }
    ...
}
```

## 启动服务端IO线程

在QuorumPeer启动start的时候，会启动NIOServerCnxnFactory线程

```java
public class QuorumPeer extends Thread implements QuorumStats.Provider {

    ...
    @Override
    public synchronized void start() {
        //从磁盘加载数据文件到内存
        loadDataBase();

        //启动服务端NIOServerCnxnFactory线程
        cnxnFactory.start();

        //初始化 leader 选举算法
        startLeaderElection();

        //启动QuorumPeer线程
        super.start();
    }
    ...
}
```

NIOServerCnxnFactory组件会初始化Selector多路复用器，当接收到客户端的连接后，对每个客户端连接封装为NIOServerCnxn组件，负责后续的客户端IO处理

```java
public void run() {
    while (!ss.socket().isClosed()) {
        try {
            //多路复用器都会有一个超时时间
            selector.select(1000);
            Set<SelectionKey> selected;
            synchronized (this) {
                selected = selector.selectedKeys();
            }
            ArrayList<SelectionKey> selectedList = new ArrayList<SelectionKey>(
                selected);
            //随机打散，避免总是先处理某个连接的请求
            Collections.shuffle(selectedList);
            for (SelectionKey k : selectedList) {
                //处理accept事件请求
                if ((k.readyOps() & SelectionKey.OP_ACCEPT) != 0) {
                    //创建客户端SocketChannel
                    SocketChannel sc = ((ServerSocketChannel) k
                                        .channel()).accept();
                    InetAddress ia = sc.socket().getInetAddress();
                    //获取指定ip的连接数
                    int cnxncount = getClientCnxnCount(ia);
                    //单个客户端连接数超过限制
                    if (maxClientCnxns > 0 && cnxncount >= maxClientCnxns){
                        LOG.warn("Too many connections from " + ia
                                 + " - max is " + maxClientCnxns );
                        sc.close();
                    } else {
                        LOG.info("Accepted socket connection from "
                                 + sc.socket().getRemoteSocketAddress());
                        //否则配置客户端SocketChannel
                        sc.configureBlocking(false);
                        //将客户端SocketChannel注册到Selector上，并关注OP_READ事件
                        SelectionKey sk = sc.register(selector,
                                                      SelectionKey.OP_READ);
                        //封装为NIOServerCnxn
                        NIOServerCnxn cnxn = createConnection(sc, sk);
                        //后续有事件触发了可以获取到这里的NIOServerCnxn
                        //经典attach做法，将socket与selectionKey绑定起来后续使用
                        sk.attach(cnxn);
                        //维护全局NIOServerCnxn
                        addCnxn(cnxn);
                    }
                } else if ((k.readyOps() & (SelectionKey.OP_READ | SelectionKey.OP_WRITE)) != 0) {
                    //如果有读写事件就绪，则通过NIOServerCnxn来处理具体IO逻辑
                    NIOServerCnxn c = (NIOServerCnxn) k.attachment();
                    c.doIO(k);
                } else {
                    if (LOG.isDebugEnabled()) {
                        LOG.debug("Unexpected ops in select "
                                  + k.readyOps());
                    }
                }
            }
            selected.clear();
        } catch (RuntimeException e) {
            LOG.warn("Ignoring unexpected runtime exception", e);
        } catch (Exception e) {
            LOG.warn("Ignoring exception", e);
        }
    }
    closeAll();
    LOG.info("NIOServerCnxn factory exited run method");
}
```

### 服务端处理accept操作

客户端发起的连接请求封装为NIOServerCnxn，并保持全局维护，在创建SocketChannel的时候就注册到Selector上并关注了OP_READ，这里封装为NIOServerCnxn后再次关注了OP_READ（多余的）

```java
public class NIOServerCnxn extends ServerCnxn {
	NIOServerCnxnFactory factory;

    SocketChannel sock;

    private final SelectionKey sk;

    boolean initialized;

    //读取客户端请求数据时使用，这些读写ByteBuffer都封装在当前客户端连接中
    //便于处理粘包与拆包等
    ByteBuffer lenBuffer = ByteBuffer.allocate(4);

    ByteBuffer incomingBuffer = lenBuffer;

    //每个客户端连接都有一个待发送消息的队列
    LinkedBlockingQueue<ByteBuffer> outgoingBuffers = new LinkedBlockingQueue<ByteBuffer>();

    int sessionTimeout;

    private final ZooKeeperServer zkServer;

    /**
     * The number of requests that have been submitted but not yet responded to.
     */
    int outstandingRequests;

    /**	
     * This is the id that uniquely identifies the session of a client. Once
     * this session is no longer active, the ephemeral nodes will go away.
     */
    long sessionId;

    static long nextSessionId = 1;
    int outstandingLimit = 1;
    
    public NIOServerCnxn(ZooKeeperServer zk, SocketChannel sock,
        SelectionKey sk, NIOServerCnxnFactory factory) throws IOException {
        this.zkServer = zk;
        this.sock = sock;
        this.sk = sk;
        this.factory = factory;
        if (this.factory.login != null) {
            this.zooKeeperSaslServer = new ZooKeeperSaslServer(factory.login);
        }
        if (zk != null) { 
            outstandingLimit = zk.getGlobalOutstandingLimit();
        }
        //禁用delay算法，避免消息延时
        sock.socket().setTcpNoDelay(true);
        /* set socket linger to false, so that socket close does not
         * block */
        //SOCKET在CLOSE时候是否等待缓冲区发送完成
        sock.socket().setSoLinger(false, -1);
        InetAddress addr = ((InetSocketAddress) sock.socket()
                .getRemoteSocketAddress()).getAddress();
        authInfo.add(new Id("ip", addr.getHostAddress()));
        //客户端连接关注OP_READ事件
        //注册的时候已经关注了OP_READ事件，这里重复而已
        sk.interestOps(SelectionKey.OP_READ);
	}
    ...
    
}
```

### 服务端处理read操作

核心步骤：

1. 处理粘包与拆包，先读取4个字节的长度
2. 再读取实际长度的消息
3. 如果read返回的是-1，可以关闭连接，这种情况一般是客户端关闭连接

处理拆包与粘包逻辑：

1. 初始化读取4字节ByteBuffer，作为消息数据的header
2. 从socket读取数据
3. 如果header未读满，则无需处理，等待下一次可读事件继续处理
4. header读满后，转换为int类型长度，并初始化为消息的实际长度，再从socket读取
5. 直到从socket读满实际消息长度数据为止
6. 重置ByteBuffer为4个字节，开始读取下一个消息

```java
boolean initialized;

ByteBuffer lenBuffer = ByteBuffer.allocate(4);

ByteBuffer incomingBuffer = lenBuffer;
```

从socket先读取4个字节，对应的是后续数据的长度

```java
//处理可读事件，消息由header(4字节)+data组成
if (k.isReadable()) {
    //incomingBuffer初始化为4个字节，读取消息header
    int rc = sock.read(incomingBuffer);
    //如果读取结果为-1抛异常(都是这么处理的)
    if (rc < 0) {
        throw new EndOfStreamException(
            "Unable to read additional data from client sessionid 0x"
            + Long.toHexString(sessionId)
            + ", likely client has closed socket");
    }
    //如果未读取到4个字节，则无需处理等下一次读事件继续来读取
    if (incomingBuffer.remaining() == 0) {
        boolean isPayload;
        //如果incomingBuffer是初始的4个字节lenBuffer，则表示读取到的是header数据
        //后续读取data数据（非header）的时候，这里是不相等的
        if (incomingBuffer == lenBuffer) { // start of next request
            incomingBuffer.flip();
            //读取4个字节的int长度，并初始化incomingBuffer为对应长度来读取data数据
            isPayload = readLength(k);
            incomingBuffer.clear();
        } else {
            // continuation
            isPayload = true;
        }
        if (isPayload) { // not the case for 4letterword
            //读取data数据
            readPayload();
        }
        else {
            // four letter words take care
            // need not do anything else
            return;
        }
    }
}
```

再读取固定长度的数据

```java
private void readPayload() throws IOException, InterruptedException {
    //数据的data未读满，继续从socket读取
    if (incomingBuffer.remaining() != 0) { // have we read length bytes?
        int rc = sock.read(incomingBuffer); // sock is non-blocking, so ok
        if (rc < 0) {
            throw new EndOfStreamException(
                "Unable to read additional data from client sessionid 0x"
                + Long.toHexString(sessionId)
                + ", likely client has closed socket");
        }
    }

    //完整data数据读取完成
    if (incomingBuffer.remaining() == 0) { // have we read length bytes?
        packetReceived();
        incomingBuffer.flip();
        //如果连接是刚创建完成，客户端发送的一定是ConnectRequest，特殊处理
        if (!initialized) {
            readConnectRequest();
        } else {
            //非ConnectRequest处理逻辑
            readRequest();
        }
        //清空lenBuffer
        lenBuffer.clear();
        //处理完一个完整请求后，重置incomingBuffer
        incomingBuffer = lenBuffer;
    }
}
```

### 服务端处理write操作

连接关注OP_WRITE的时机是读取消息后，如果有需要发送响应的消息，在加入到outgoingBuffers队列后，会将当前连接关注OP_WRITE。如果发生拆包，则放在队列头部，继续在下一次OP_WRITE事件继续发送，直到发送完成再从队列移除即可

有一个DirectByteBuffer对外内存的优化，每次发送固定大小的DirectByteBuffer，直到发送队列中的数据发送完成，并从队列移除。针对当前客户端连接，处理完OP_WRITE后需要判断outgoingBuffers队列是否还有数据需要发送给客户端，如果没有则取消关注OP_WRITE，避免后续无效的处理OP_WRITE事件

```java
//处理可写事件
//处理的拆包粘包，另一种经典方式
if (k.isWritable()) {
    if (outgoingBuffers.size() > 0) {
        /*
         * This is going to reset the buffer position to 0 and the
         * limit to the size of the buffer, so that we can fill it
         * with data from the non-direct buffers that we need to
         * send.
         */
        //使用堆外内存提升性能，每满64K才进行后续网络发送
        ByteBuffer directBuffer = factory.directBuffer;
        directBuffer.clear();

        //directBuffer大小是64K
        for (ByteBuffer b : outgoingBuffers) {
            //如果directBuffer小于outgoingBuffers队列中需要发送的数据，则进行数据分割
            if (directBuffer.remaining() < b.remaining()) {
                /*
                 * When we call put later, if the directBuffer is to
                 * small to hold everything, nothing will be copied,
                 * so we've got to slice the buffer if it's too big.
                 */
                b = (ByteBuffer) b.slice().limit(
                    directBuffer.remaining());
            }
            /*
             * put() is going to modify the positions of both
             * buffers, put we don't want to change the position of
             * the source buffers (we'll do that after the send, if
             * needed), so we save and reset the position after the
             * copy
             */
            //如果directBuffer大于outgoingBuffers队列中需要发送的数据，则直接将队列中数据放入到directBuffer
            int p = b.position();
            directBuffer.put(b);
            b.position(p);
            //如果directBuffer空间被写满了则停止循环进行后续数据发送
            if (directBuffer.remaining() == 0) {
                break;
            }
        }
        /*
         * Do the flip: limit becomes position, position gets set to
         * 0. This sets us up for the write.
         */
        directBuffer.flip();

        //直接将directBuffer通过网络IO发送出去
        int sent = sock.write(directBuffer);
        ByteBuffer bb;

        // Remove the buffers that we have sent
        //前面发送的只是directBuffer,outgoingBuffers队列中的数据不会有变化
            while (outgoingBuffers.size() > 0) {
            bb = outgoingBuffers.peek();
            if (bb == ServerCnxnFactory.closeConn) {
                throw new CloseRequestException("close requested");
            }
            int left = bb.remaining() - sent;
            //left>0表示outgoingBuffers队列中第一个ByteBuffer还没有发送完成
            if (left > 0) {
                /*
                 * We only partially sent this buffer, so we update
                 * the position and exit the loop.
                 */
                //定位到已经发送到的位置
                //后续继续发送
                bb.position(bb.position() + sent);
                break;
            }
            //left ==0 表示全部发送完成
            packetSent();
            /* We've sent the whole buffer, so drop the buffer */
            sent -= bb.remaining();
            //从outgoingBuffers队列中移除第一个已经发送完成的ByteBuffer
            outgoingBuffers.remove();
        }
        // ZooLog.logTraceMessage(LOG,
        // ZooLog.CLIENT_DATA_PACKET_TRACE_MASK, "after send,
        // outgoingBuffers.size() = " + outgoingBuffers.size());
    }

    //判断当前连接是否还需要继续关注OP_WRITE
    //查看outgoingBuffers队列是否已经发送完成，并且确定是否继续关注OP_WRITE事件
    synchronized(this.factory){
        if (outgoingBuffers.size() == 0) {
            if (!initialized
                && (sk.interestOps() & SelectionKey.OP_READ) == 0) {
                throw new CloseRequestException("responded to info probe");
            }
            sk.interestOps(sk.interestOps()
                           & (~SelectionKey.OP_WRITE));
        } else {
            sk.interestOps(sk.interestOps()
                           | SelectionKey.OP_WRITE);
        }
    }
}
```

# 客户端NIO通信流程

## ZooKeeper客户端组件

在客户端创建好与server的连接时，zk服务端会给每个客户端连接生成唯一sessionId，并且客户端会定期发送心跳给server来保持session有效性。一旦客户端超过一定时间没有发送心跳，将导致该session失效，无法再调用任何api操作，只能再创建新的客户端来进行有效操作。客户端的操作都有同步和异步，同步操作将会阻塞直到server返回响应；异步操作将加入队列后直接返回，在server返回响应后执行对应的回调

可以在server注册一些watch，一旦客户端进行了某些api操作，server会触发这些watch，然后发送对应的event给指定客户端。随后watch将会失效，也就是只会被触发一次。客户端需要实现watcher接口，来处理server发送的event事件

核心流程：

1. 初始化客户端组件ZooKeeper，将连接封装为ClientCnxn
2. 启动sendThread线程负责IO处理、eventThread线程负责事件回调
3. 客户端给服务端发送消息后，会阻塞等待响应

```java
/**
 * Session创建是异步的，该构造方法在发起与server的连接后将会直接返回，此时可能连接并未完全创建完成
 * ZooKeeper客户端会从连接串挑选任意一个server来发起连接，如果失败了，将会重试连接其他server。从3.2.0版本添加了chroot，对所有的api操作，都会基于该路径
 */
public class ZooKeeper {
    ...
    public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher,
            boolean canBeReadOnly)
        throws IOException
    {
        LOG.info("Initiating client connection, connectString=" + connectString
                + " sessionTimeout=" + sessionTimeout + " watcher=" + watcher);

        //默认端口号2181
        ConnectStringParser connectStringParser = new ConnectStringParser(
                connectString);
        HostProvider hostProvider = new StaticHostProvider(
                connectStringParser.getServerAddresses());

        //构建代表客户端连接的ClientCnxn
        //getClientCnxnSocket()方法创建的是ClientCnxnSocketNIO对象
        cnxn = new ClientCnxn(connectStringParser.getChrootPath(),
                hostProvider, sessionTimeout, this, watchManager,
                getClientCnxnSocket(), canBeReadOnly);
        //启动ClientCnxn
        cnxn.start();
    }
    ...
}
```

客户端会被封装为ClientCnxn组件来维护

```java
public class ClientCnxn {
    ...
    /**
     * These are the packets that have been sent and are waiting for a response.
     * 当前客户端连接待接收消息队列
     */
    private final LinkedList<Packet> pendingQueue = new LinkedList<Packet>();

    /**
     * These are the packets that need to be sent.
     * 当前客户端连接待发送消息队列
     */
    private final LinkedList<Packet> outgoingQueue = new LinkedList<Packet>();
    //客户端组件
    private final ZooKeeper zooKeeper;
    private long sessionId;
    //负责IO处理
    final SendThread sendThread;
    //负责事件回调
    final EventThread eventThread;
    ...
}
```

通过start方法启动ClientCnxn后，会启动SendThread和EventThread线程

```java
public void start() {
    sendThread.start();
    eventThread.start();
}
```

## 启动sendThread线程处理客户端IO操作

线程启动的时候会进行一次向服务端发起connect请求，因为是非阻塞，所以可能连接不会马上建立完成，后续doTransport方法会处理。连接成功建立后，后续会定时发送ping心跳请求。最重要的是，线程会负责执行与服务端的IO操作

```java
@Override
public void run() {
    //绑定sendThread和sessionId
    clientCnxnSocket.introduce(this,sessionId);
    //更新时间
    clientCnxnSocket.updateNow();
    //更新最近发送消息时间
    clientCnxnSocket.updateLastSendAndHeard();
    int to;
    long lastPingRwServer = System.currentTimeMillis();
    while (state.isAlive()) {
        try {
            if (!clientCnxnSocket.isConnected()) {
                if(!isFirstConnect){
                    try {
                        Thread.sleep(r.nextInt(1000));
                    } catch (InterruptedException e) {
                        LOG.warn("Unexpected exception", e);
                    }
                }
                // don't re-establish connection if we are closing
                if (closing || !state.isAlive()) {
                    break;
                }
                //创建与server的连接
                startConnect();
                //再次更新最近发送消息时间
                clientCnxnSocket.updateLastSendAndHeard();
            }

            if (state.isConnected()) {
                // determine whether we need to send an AuthFailed event.
                if (zooKeeperSaslClient != null) {
                    boolean sendAuthEvent = false;
                    if (zooKeeperSaslClient.getSaslState() == ZooKeeperSaslClient.SaslState.INITIAL) {
                        try {
                            zooKeeperSaslClient.initialize(ClientCnxn.this);
                        } catch (SaslException e) {
                            LOG.error("SASL authentication with Zookeeper Quorum member failed: " + e);
                            state = States.AUTH_FAILED;
                            sendAuthEvent = true;
                        }
                    }
                    KeeperState authState = zooKeeperSaslClient.getKeeperState();
                    if (authState != null) {
                        if (authState == KeeperState.AuthFailed) {
                            // An authentication error occurred during authentication with the Zookeeper Server.
                            state = States.AUTH_FAILED;
                            sendAuthEvent = true;
                        } else {
                            if (authState == KeeperState.SaslAuthenticated) {
                                sendAuthEvent = true;
                            }
                        }
                    }

                    if (sendAuthEvent == true) {
                        eventThread.queueEvent(new WatchedEvent(
                            Watcher.Event.EventType.None,
                            authState,null));
                    }
                }
                //readTimeout = sessionTimeout * 2 / 3
                //如果连接已经创建用readTimeout来计算超时时间
                to = readTimeout - clientCnxnSocket.getIdleRecv();
            } else {
                //否则用连接时间connectTimeout来计算超时时间
                to = connectTimeout - clientCnxnSocket.getIdleRecv();
            }

            if (to <= 0) {
                //session超时报错
                throw new SessionTimeoutException(
                    "Client session timed out, have not heard from server in "
                    + clientCnxnSocket.getIdleRecv() + "ms"
                    + " for sessionid 0x"
                    + Long.toHexString(sessionId));
            }
            if (state.isConnected()) {
                //达到超时时间的一半就需要发送心跳
                int timeToNextPing = readTimeout / 2
                    - clientCnxnSocket.getIdleSend();
                if (timeToNextPing <= 0) {
                    //发送心跳
                    sendPing();
                    //更新连接的lastSend
                    clientCnxnSocket.updateLastSend();
                } else {
                    if (timeToNextPing < to) {
                        to = timeToNextPing;
                    }
                }
            }

            // If we are in read-only mode, seek for read/write server
            if (state == States.CONNECTEDREADONLY) {
                long now = System.currentTimeMillis();
                int idlePingRwServer = (int) (now - lastPingRwServer);
                if (idlePingRwServer >= pingRwTimeout) {
                    lastPingRwServer = now;
                    idlePingRwServer = 0;
                    pingRwTimeout =
                        Math.min(2*pingRwTimeout, maxPingRwTimeout);
                    pingRwServer();
                }
                to = Math.min(to, pingRwTimeout - idlePingRwServer);
            }

            //执行IO事件
            clientCnxnSocket.doTransport(to, pendingQueue, outgoingQueue, ClientCnxn.this);
        } catch (Throwable e) {
            if (closing) {
                if (LOG.isDebugEnabled()) {
                    // closing so this is expected
                    LOG.debug("An exception was thrown while closing send thread for session 0x"
                              + Long.toHexString(getSessionId())
                              + " : " + e.getMessage());
                }
                break;
            } else {
                // this is ugly, you have a better way speak up
                if (e instanceof SessionExpiredException) {
                    LOG.info(e.getMessage() + ", closing socket connection");
                } else if (e instanceof SessionTimeoutException) {
                    LOG.info(e.getMessage() + RETRY_CONN_MSG);
                } else if (e instanceof EndOfStreamException) {
                    LOG.info(e.getMessage() + RETRY_CONN_MSG);
                } else if (e instanceof RWServerFoundException) {
                    LOG.info(e.getMessage());
                } else {
                    LOG.warn(
                        "Session 0x"
                        + Long.toHexString(getSessionId())
                        + " for server "
                        + clientCnxnSocket.getRemoteSocketAddress()
                        + ", unexpected error"
                        + RETRY_CONN_MSG, e);
                }
                cleanup();
                if (state.isAlive()) {
                    eventThread.queueEvent(new WatchedEvent(
                        Event.EventType.None,
                        Event.KeeperState.Disconnected,
                        null));
                }
                clientCnxnSocket.updateNow();
                clientCnxnSocket.updateLastSendAndHeard();
            }
        }
    }
    //关闭后的资源清理
    cleanup();
    //客户端连接关闭
    clientCnxnSocket.close();
    if (state.isAlive()) {
        eventThread.queueEvent(new WatchedEvent(Event.EventType.None,
                                                Event.KeeperState.Disconnected, null));
    }
    ZooTrace.logTraceMessage(LOG, ZooTrace.getTextTraceLevel(),
                             "SendThread exitedloop.");
}
```

客户端zookeeper初始化的时候，会初始化ClientCnxnSocketNIO组件，组件持有Selector组件，也就是每个客户端连接都是各自自己的Selector，用来处理IO

```java
@Override
void doTransport(int waitTimeOut, List<Packet> pendingQueue, LinkedList<Packet> outgoingQueue,
                 ClientCnxn cnxn)
    throws IOException, InterruptedException {
    //获取准备就绪事件
    //每个客户端都会持有自己的Selector
    selector.select(waitTimeOut);
    Set<SelectionKey> selected;
    synchronized (this) {
        selected = selector.selectedKeys();
    }
    // Everything below and until we get back to the select is
    // non blocking, so time is effectively a constant. That is
    // Why we just have to do this once, here
    updateNow();
    for (SelectionKey k : selected) {
        SocketChannel sc = ((SocketChannel) k.channel());
        if ((k.readyOps() & SelectionKey.OP_CONNECT) != 0) {
            //处理连接成功事件
            if (sc.finishConnect()) {
                //更新最新有效时间
                updateLastSendAndHeard();
                //发送ConnectRequest消息
                sendThread.primeConnection();
            }
        } else if ((k.readyOps() & (SelectionKey.OP_READ | SelectionKey.OP_WRITE)) != 0) {
            //处理读写事件
            doIO(pendingQueue, outgoingQueue, cnxn);
        }
    }
    
    //每次执行完一轮select后，判断是否有数据需要发送出去，并关注OP_WRITE
    //并在执行具体的OP_WRITE逻辑的时候，每发送完一个数据，都会判断是否还需要继续关注OP_WRITE
    if (sendThread.getZkState().isConnected()) {
        synchronized(outgoingQueue) {
            if (findSendablePacket(outgoingQueue,
                                   cnxn.sendThread.clientTunneledAuthenticationInProgress()) != null) {
                enableWrite();
            }
        }
    }
    selected.clear();
}
```

### 客户端发起connect连接

客户端的startConnect方法最终是调用如下方法进行网络连接

```java
@Override
void connect(InetSocketAddress addr) throws IOException {
    //创建SocketChannel
    SocketChannel sock = createSock();
    try {
        //注册并发起连接
        registerAndConnect(sock, addr);
    } catch (IOException e) {
        LOG.error("Unable to open socket to " + addr);
        sock.close();
        throw e;
    }
    initialized = false;

    /*
     * Reset incomingBuffer
     */
    lenBuffer.clear();
    incomingBuffer = lenBuffer;
}
```

socket参数配置

```java
SocketChannel createSock() throws IOException {
    SocketChannel sock;
    sock = SocketChannel.open();
    sock.configureBlocking(false);
    sock.socket().setSoLinger(false, -1);
    sock.socket().setTcpNoDelay(true);
    return sock;
}
```

注册到多路复用器上，并关注OP_CONNECT事件，同时会主动创建与server的网络连接，如果连接创建成功则向server发送ConnectRequest类型请求，server端接收到该请求会生成唯一sessionId

```java
void registerAndConnect(SocketChannel sock, InetSocketAddress addr) 
    throws IOException {
    //注册并关注OP_CONNECT事件
    sockKey = sock.register(selector, SelectionKey.OP_CONNECT);
    //直接发起连接，因为是异步非阻塞，可能会返回false
    //如果是与本地服务端建立连接，则很快会返回true，否则一般都会返回false
    boolean immediateConnect = sock.connect(addr);
    if (immediateConnect) {
        sendThread.primeConnection();
    }
}
```

连接创建成功后发送ConnectRequest请求

```java
/**
 * 建立连接后发送ConnectRequest数据包和认证数据
 * 并且开始关注OP_READ和OP_WRITE事件
 * @throws IOException
 */
void primeConnection() throws IOException {
    LOG.info("Socket connection established to "
             + clientCnxnSocket.getRemoteSocketAddress()
             + ", initiating session");
    isFirstConnect = false;
    long sessId = (seenRwServerBefore) ? sessionId : 0;
    ConnectRequest conReq = new ConnectRequest(0, lastZxid,
                                               sessionTimeout, sessId, sessionPasswd);
    synchronized (outgoingQueue) {
        // We add backwards since we are pushing into the front
        // Only send if there's a pending watch
        // TODO: here we have the only remaining use of zooKeeper in
        // this class. It's to be eliminated!
        if (!disableAutoWatchReset) {
            List<String> dataWatches = zooKeeper.getDataWatches();
            List<String> existWatches = zooKeeper.getExistWatches();
            List<String> childWatches = zooKeeper.getChildWatches();
            if (!dataWatches.isEmpty()
                || !existWatches.isEmpty() || !childWatches.isEmpty()) {
                SetWatches sw = new SetWatches(lastZxid,
                                               prependChroot(dataWatches),
                                               prependChroot(existWatches),
                                               prependChroot(childWatches));
                RequestHeader h = new RequestHeader();
                h.setType(ZooDefs.OpCode.setWatches);
                h.setXid(-8);
                Packet packet = new Packet(h, new ReplyHeader(), sw, null, null);
                outgoingQueue.addFirst(packet);
            }
        }

        //添加认证信息到队列
        for (AuthData id : authInfo) {
            outgoingQueue.addFirst(new Packet(new RequestHeader(-4,
                                                                OpCode.auth), null, new AuthPacket(0, id.scheme,
                                                                                                   id.data), null, null));
        }
        //发送conReq数据包
        outgoingQueue.addFirst(new Packet(null, null, conReq,
                                          null, null, readOnly));
    }
    //关注读和写事件
    clientCnxnSocket.enableReadWriteOnly();
    if (LOG.isDebugEnabled()) {
        LOG.debug("Session establishment request sent on "
                  + clientCnxnSocket.getRemoteSocketAddress());
    }
}
```

### 客户端执行read操作

客户端与server创建连接时，如果创建成功则会发送ConnectRequest给server，server会生成代表客户端唯一sessionId。这里在读取server发送的数据时，如果是第一次读取，则会处理特殊的ConnectResponse，客户端会读取sessionId来标识当前客户端。非第一次接收的ConnectResponse响应都会执行readResponse逻辑，处理业务io数据

```java
//处理读IO
//1.首先初始化incomingBuffer为4个字节，并从socket读取数据，直到读取到4个字节
//2.将读取到的4个字节转换成int类型，代表后续需要读取的数据的长度，并初始化为incomingBuffer的长度
//3.继续从socket读取数据，直到读取上述int长度数据为止，也就是incomingBuffer不为空
//4.在对服务端成功创建连接后，会发送ConnectRequest请求，并且initialized是false
//5.这里socket第一次会执行else if逻辑，读取ConnectResponse响应数据，来设置当前客户端sessionId
//6.后续接收到数据后，会从pendingQueue中移除待响应数据
if (sockKey.isReadable()) {
    //先读取4个字节
    int rc = sock.read(incomingBuffer);
    if (rc < 0) {
        throw new EndOfStreamException(
            "Unable to read additional data from server sessionid 0x"
            + Long.toHexString(sessionId)
            + ", likely server has closed socket");
    }
    //如果没有读取到4个字节，不用处理，下一次select会继续来读取
    //并且incomingBuffer没有被清空，会继续读满4个字节
    if (!incomingBuffer.hasRemaining()) {
        incomingBuffer.flip();
        //第1次读取4个字节，这里条件满足
        //第2次incomingBuffer被初始化为上述4个字节长度的ByteBuffer，这里条件就不会满足
        if (incomingBuffer == lenBuffer) {
            recvCount++;
            //读取到字节长度后，重新初始化了incomingBuffer
            readLength();
        } else if (!initialized) {
            //initialized默认为false
            //读取服务端响应数据ConnectResponse，设置当前客户端sessionId并且触发event事件
            readConnectResult();
            //如果没有关注OP_READ则继续关注
            enableRead();
            //如果有数据需要发送则并且没有关注OP_WRITE则关注OP_WRITE
            if (findSendablePacket(outgoingQueue,
                                   cnxn.sendThread.clientTunneledAuthenticationInProgress()) != null) {
                // Since SASL authentication has completed (if client is configured to do so),
                // outgoing packets waiting in the outgoingQueue can now be sent.
                enableWrite();
            }
            lenBuffer.clear();
            incomingBuffer = lenBuffer;
            updateLastHeard();
            //修改标识，只会再第一次执行该else if逻辑
            initialized = true;
        } else {
            //在第一次读取完ConnectResponse后，后续读取数据逻辑都是这里
            sendThread.readResponse(incomingBuffer);
            //重置缓冲区
            lenBuffer.clear();
            incomingBuffer = lenBuffer;
            //更新最近接收时间
            updateLastHeard();
        }
    }
}
```

客户端发送完成并在等待响应的消息会加入到pendingQueue队列，等待接收到对应响应数据后从pendingQueue队列删除

```java
//解析读取的请求
void readResponse(ByteBuffer incomingBuffer) throws IOException {
    ByteBufferInputStream bbis = new ByteBufferInputStream(
        incomingBuffer);
    BinaryInputArchive bbia = BinaryInputArchive.getArchive(bbis);
    ReplyHeader replyHdr = new ReplyHeader();

    replyHdr.deserialize(bbia, "header");
    ...

    //接收到的响应数据一定对应的是pendingQueue队列队头
    Packet packet;
    synchronized (pendingQueue) {
        if (pendingQueue.size() == 0) {
            throw new IOException("Nothing in the queue, but got "
                                  + replyHdr.getXid());
        }
        packet = pendingQueue.remove();
    }
    /*
     * Since requests are processed in order, we better get a response
     * to the first request!
     */
    try {
        if (packet.requestHeader.getXid() != replyHdr.getXid()) {
            packet.replyHeader.setErr(
                KeeperException.Code.CONNECTIONLOSS.intValue());
            throw new IOException("Xid out of order. Got Xid "
                                  + replyHdr.getXid() + " with err " +
                                  + replyHdr.getErr() +
                                  " expected Xid "
                                  + packet.requestHeader.getXid()
                                  + " for a packet with details: "
                                  + packet );
        }

        packet.replyHeader.setXid(replyHdr.getXid());
        packet.replyHeader.setErr(replyHdr.getErr());
        packet.replyHeader.setZxid(replyHdr.getZxid());
        if (replyHdr.getZxid() > 0) {
            lastZxid = replyHdr.getZxid();
        }
        if (packet.response != null && replyHdr.getErr() == 0) {
            //序列化解析请求
            packet.response.deserialize(bbia, "response");
        }

        if (LOG.isDebugEnabled()) {
            LOG.debug("Reading reply sessionid:0x"
                      + Long.toHexString(sessionId) + ", packet:: " + packet);
        }
    } finally {
        //读取完数据包后的处理
        finishPacket(packet);
    }
}
```

客户端给客户端发送完请求后，也就是submitRequest方法，会阻塞等待finished字段不为false。在这里客户端读取完请求后，会将finished设置为true，客户端就可以返回了

```java
private void finishPacket(Packet p) {
    if (p.watchRegistration != null) {
        p.watchRegistration.register(p.replyHeader.getErr());
    }

    //如果有回调则执行
    if (p.cb == null) {
        synchronized (p) {
            p.finished = true;
            p.notifyAll();
        }
    } else {
        p.finished = true;
        eventThread.queuePacket(p);
    }
}
```

### 客户端执行write操作

客户端需要发送的数据都会加入到outgoingQueue队列中，在执行可写事件时，从outgoingQueue队列获取一个数据进行网络传输，如果发生粘包与拆包没有发送完成，则消息继续存在于outgoingQueue队列队头中，下一次执行可写事件继续发送。发送完成的消息加入到pendingQueue队列中，并从outgoingQueue队列中移除

每次发送完一个完整消息，都通过判断outgoingQueue队列是否还有待发送消息来确定是否需要取消关注OP_WRITE

```java
//处理写IO
if (sockKey.isWritable()) {
    synchronized(outgoingQueue) {
        //获取队列需要发送的数据包
        Packet p = findSendablePacket(outgoingQueue,
                                      cnxn.sendThread.clientTunneledAuthenticationInProgress());

        if (p != null) {
            //更新最近发送时间
            updateLastSend();
            // If we already started writing p, p.bb will already exist
            if (p.bb == null) {
                if ((p.requestHeader != null) &&
                    (p.requestHeader.getType() != OpCode.ping) &&
                    (p.requestHeader.getType() != OpCode.auth)) {
                    p.requestHeader.setXid(cnxn.getXid());
                }
                //序列化需要发送的数据，并且添加header长度
                p.createBB();
            }
            //将数据通过socket发送出去
            //如果发生粘包拆包继续发送
            sock.write(p.bb);
            if (!p.bb.hasRemaining()) {
                //如果发送完成，则从outgoingQueue队列移除，并且添加到pendingQueue队列中
                sentCount++;
                outgoingQueue.removeFirstOccurrence(p);
                //connectRequest请求的requestHeader是null，因此不会加入到pendingQueue队列
                //ping、auth类型的请求都不会加入到pendingQueue队列
                if (p.requestHeader != null
                    && p.requestHeader.getType() != OpCode.ping
                    && p.requestHeader.getType() != OpCode.auth) {
                    synchronized (pendingQueue) {
                        pendingQueue.add(p);
                    }
                }
            }
        }
        //如果outgoingQueue还有数据包需要发送则继续关注OP_WRITE事件
        if (outgoingQueue.isEmpty()) {
            // No more packets to send: turn off write interest flag.
            // Will be turned on later by a later call to enableWrite(),
            // from within ZooKeeperSaslClient (if client is configured
            // to attempt SASL authentication), or in either doIO() or
            // in doTransport() if not.
            disableWrite();
        } else {
            // Just in case
            enableWrite();
        }
    }
}
```

数据序列化逻辑为如下，先写4个字节的后面消息长度，再写真实消息数据

```java
public void createBB() {
    try {
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        BinaryOutputArchive boa = BinaryOutputArchive.getArchive(baos);
        boa.writeInt(-1, "len"); // We'll fill this in later
        if (requestHeader != null) {
            requestHeader.serialize(boa, "header");
        }
        if (request instanceof ConnectRequest) {
            request.serialize(boa, "connect");
            // append "am-I-allowed-to-be-readonly" flag
            boa.writeBool(readOnly, "readOnly");
        } else if (request != null) {
            request.serialize(boa, "request");
        }
        baos.close();
        this.bb = ByteBuffer.wrap(baos.toByteArray());
        //前面已经将-1写进去了，这里覆盖真实长度即可
        this.bb.putInt(this.bb.capacity() - 4);
        this.bb.rewind();
    } catch (IOException e) {
        LOG.warn("Ignoring unexpected exception", e);
    }
}
```
## 启动EventThread线程处理事件通知？

# 流程图

![客户端与服务端网络模型 (1)](D:\user\文档\cl\doc\zk\3.客户端与服务端网络通信模型.assets\客户端与服务端网络模型 (1).jpg)

# 架构经验

- 网络通信的自定义数据协议与粘包拆包的处理
- 服务端接收到客户端请求时，将SocketChannel与SelectionKey封装到一起后进行attach

# QA问题

OP_WRITE到底是什么时候就绪的？

写就绪相对有一点特殊，一般来说，你不应该注册写事件。写操作的就绪条件为底层缓冲区有空闲空间，而写缓冲区绝大部分时间都是有空闲空间的，所以当你注册写事件后，写操作一直是就绪的，选择处理线程全占用整个CPU资源。所以，只有当你确实有数据要写时再注册写操作，并在写完以后马上取消注册